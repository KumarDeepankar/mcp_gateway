from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver

from .state_definition import SearchAgentState
from .nodes import (
    initialize_search_node,
    discover_tools_node,
    planning_node,
    prepare_next_step_node,
    execute_tool_step_node,
    execute_unified_reasoning_and_response_node,
    generate_final_response_node,
    unified_planning_decision_node
)


# --- Conditional Edges ---

def route_after_planning(state: SearchAgentState) -> str:
    """Route after planning is complete"""
    if state.get("error_message"):
        return "__end__"

    if state.get("plan"):
        return "prepare_next_step_node"
    else:
        return "generate_final_response_node"


def route_after_step_preparation(state: SearchAgentState) -> str:
    """Route after preparing the next step"""
    if state.get("error_message"):
        return "__end__"

    current_step = state.get("current_step_to_execute")

    if not current_step:
        # No more steps, generate final response
        return "generate_final_response_node"

    if current_step.step_type == "TOOL_CALL":
        return "execute_tool_step_node"
    elif current_step.step_type == "REASONING_STEP":
        return "execute_unified_reasoning_and_response_node"
    else:
        return "generate_final_response_node"


def route_after_execution(state: SearchAgentState) -> str:
    """Route after executing a step"""
    if state.get("error_message"):
        return "__end__"

    # Check if there are more steps
    plan = state.get("plan", [])
    current_index = state.get("current_step_index", 0)

    if current_index < len(plan):
        return "prepare_next_step_node"
    else:
        return "generate_final_response_node"


def route_after_unified_reasoning(state: SearchAgentState) -> str:
    """Route after unified reasoning and response node"""
    if state.get("error_message"):
        return "__end__"

    # Check if final response was generated by the unified node
    if state.get("final_response_generated_flag"):
        return "__end__"

    # Otherwise continue with plan execution
    plan = state.get("plan", [])
    current_index = state.get("current_step_index", 0)

    if current_index < len(plan):
        return "prepare_next_step_node"
    else:
        return "generate_final_response_node"


def route_after_final_response(state: SearchAgentState) -> str:
    """Route after generating final response"""
    return "__end__"


# --- Graph Definition ---
checkpointer = MemorySaver()
workflow = StateGraph(SearchAgentState)

# Add nodes
workflow.add_node("initialize_search_node", initialize_search_node)
workflow.add_node("discover_tools_node", discover_tools_node)
workflow.add_node("planning_node", planning_node)
workflow.add_node("prepare_next_step_node", prepare_next_step_node)
workflow.add_node("execute_tool_step_node", execute_tool_step_node)
workflow.add_node("execute_unified_reasoning_and_response_node", execute_unified_reasoning_and_response_node)
workflow.add_node("generate_final_response_node", generate_final_response_node)

# Define edges
workflow.set_entry_point("initialize_search_node")
workflow.add_edge("initialize_search_node", "discover_tools_node")
workflow.add_edge("discover_tools_node", "planning_node")

# Conditional routing after planning
workflow.add_conditional_edges(
    "planning_node",
    route_after_planning,
    {
        "prepare_next_step_node": "prepare_next_step_node",
        "generate_final_response_node": "generate_final_response_node",
        "__end__": END
    }
)

# Conditional routing after step preparation
workflow.add_conditional_edges(
    "prepare_next_step_node",
    route_after_step_preparation,
    {
        "execute_tool_step_node": "execute_tool_step_node",
        "execute_unified_reasoning_and_response_node": "execute_unified_reasoning_and_response_node",
        "generate_final_response_node": "generate_final_response_node",
        "__end__": END
    }
)

# After execution, check for more steps
workflow.add_conditional_edges(
    "execute_tool_step_node",
    route_after_execution,
    {
        "prepare_next_step_node": "prepare_next_step_node",
        "generate_final_response_node": "generate_final_response_node",
        "__end__": END
    }
)

workflow.add_conditional_edges(
    "execute_unified_reasoning_and_response_node",
    route_after_unified_reasoning,
    {
        "prepare_next_step_node": "prepare_next_step_node",
        "generate_final_response_node": "generate_final_response_node",
        "__end__": END
    }
)

# Final response always ends
workflow.add_conditional_edges(
    "generate_final_response_node",
    route_after_final_response,
    {
        "__end__": END
    }
)

compiled_agent = workflow.compile(checkpointer=checkpointer)


# --- OPTIMIZED 2-LLM-CALL WORKFLOW ---

def route_after_unified_decision(state: SearchAgentState) -> str:
    """Route after unified planning and decision"""
    if state.get("error_message"):
        return "__end__"

    if state.get("final_response_generated_flag"):
        return "__end__"

    # If we have a plan, prepare the next step
    plan = state.get("plan", [])
    if plan:
        return "prepare_next_step_node"
    else:
        return "__end__"


def optimized_route_after_step_preparation(state: SearchAgentState) -> str:
    """Route after preparing the next step in optimized workflow"""
    if state.get("error_message"):
        return "unified_planning_decision_node"

    current_step = state.get("current_step_to_execute")

    if not current_step:
        return "unified_planning_decision_node"

    if current_step.step_type == "TOOL_CALL":
        return "execute_tool_step_node"
    elif current_step.step_type == "REASONING_STEP":
        return "execute_unified_reasoning_and_response_node"
    else:
        return "unified_planning_decision_node"


# Optimized workflow with only 2 LLM calls
optimized_checkpointer = MemorySaver()
optimized_workflow = StateGraph(SearchAgentState)

# Add nodes for optimized workflow
optimized_workflow.add_node("initialize_search_node", initialize_search_node)
optimized_workflow.add_node("discover_tools_node", discover_tools_node)
optimized_workflow.add_node("unified_planning_decision_node", unified_planning_decision_node)
optimized_workflow.add_node("prepare_next_step_node", prepare_next_step_node)
optimized_workflow.add_node("execute_tool_step_node", execute_tool_step_node)
optimized_workflow.add_node("execute_unified_reasoning_and_response_node", execute_unified_reasoning_and_response_node)

# Define optimized edges
optimized_workflow.set_entry_point("initialize_search_node")
optimized_workflow.add_edge("initialize_search_node", "discover_tools_node")
optimized_workflow.add_edge("discover_tools_node", "unified_planning_decision_node")

# Conditional routing after unified decision
optimized_workflow.add_conditional_edges(
    "unified_planning_decision_node",
    route_after_unified_decision,
    {
        "prepare_next_step_node": "prepare_next_step_node",
        "__end__": END
    }
)

# Route after step preparation (optimized version)
optimized_workflow.add_conditional_edges(
    "prepare_next_step_node",
    optimized_route_after_step_preparation,
    {
        "execute_tool_step_node": "execute_tool_step_node",
        "execute_unified_reasoning_and_response_node": "execute_unified_reasoning_and_response_node",
        "unified_planning_decision_node": "unified_planning_decision_node"
    }
)

# After execution, always go back to unified decision node
optimized_workflow.add_edge("execute_tool_step_node", "unified_planning_decision_node")
optimized_workflow.add_edge("execute_unified_reasoning_and_response_node", "unified_planning_decision_node")

# Compile optimized agent
optimized_compiled_agent = optimized_workflow.compile(checkpointer=optimized_checkpointer)